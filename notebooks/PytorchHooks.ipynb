{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example PyTorch model\n",
    "```\n",
    "          +--+  z1  +--+  z2\n",
    "     +--->|La|----->|Lb|-----+\n",
    "     |    +--+      +--+     |\n",
    " x   |                       |   +--+ (o1,o2)\n",
    "-----+                       +-->|SD|------->\n",
    "     |                       |   +--+\n",
    "     |    +--+ h1            |\n",
    "     +--->+Lb+---------------+\n",
    "          +--+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from typing import Callable, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class SumDiff(torch.nn.Module):\n",
    "    def forward(self, a, b):\n",
    "        return a + b, a - b\n",
    "\n",
    "\n",
    "class LinearA(torch.nn.Linear):\n",
    "    pass\n",
    "\n",
    "\n",
    "class LinearB(torch.nn.Linear):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_a = LinearA(2, 2)\n",
    "        self.linear_b = LinearB(2, 4, bias=False)\n",
    "        self.sum_diff = SumDiff()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.linear_a(x)\n",
    "        z2 = self.linear_b(z1)\n",
    "        h1 = self.linear_b(x)\n",
    "        o1, o2 = self.sum_diff(z2, h1)\n",
    "        out = o1 / o2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x   : (3, 2)\n",
      "grad: (3, 2)\n",
      "out : (3, 4)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 2).requires_grad_()\n",
    "net = Net()\n",
    "out = net(x)\n",
    "out.backward(torch.ones_like(out))\n",
    "print(\n",
    "    f\"x   : {tuple(x.shape)}\",\n",
    "    f\"grad: {tuple(x.grad.shape)}\",\n",
    "    f\"out : {tuple(out.shape)}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module forward hook\n",
    "A module forward hook runs after the module output is computed. It received the input and output tensors of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearA\n",
      "IN[0]  (3, 2) b1c0\n",
      "OUT[0] (3, 2) ccc0\n",
      "\n",
      "LinearB\n",
      "IN[0]  (3, 2) ccc0\n",
      "OUT[0] (3, 4) 41c0\n",
      "\n",
      "LinearB\n",
      "IN[0]  (3, 2) b1c0\n",
      "OUT[0] (3, 4) ce00\n",
      "\n",
      "SumDiff\n",
      "IN[0]  (3, 4) 41c0\n",
      "IN[1]  (3, 4) ce00\n",
      "OUT[0] (3, 4) b680\n",
      "OUT[1] (3, 4) 4240\n",
      "\n",
      "Net\n",
      "IN[0]  (3, 2) b1c0\n",
      "OUT[0] (3, 4) 4280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tensor_hex(tensor: torch.Tensor) -> str:\n",
    "    return hex(id(tensor))[-4:]\n",
    "\n",
    "\n",
    "def module_forward_hook(\n",
    "    module: torch.nn.Module,\n",
    "    inputs: Tuple[torch.Tensor],\n",
    "    outputs: Union[torch.Tensor, Tuple[torch.Tensor]],\n",
    ") -> Optional[torch.Tensor]:\n",
    "    print(module.__class__.__name__)\n",
    "    if not isinstance(outputs, tuple):\n",
    "        outputs = (outputs,)\n",
    "    for idx, t in enumerate(inputs):\n",
    "        print(f\"IN[{idx}]  {tuple(t.shape)} {tensor_hex(t)}\")\n",
    "    for idx, t in enumerate(outputs):\n",
    "        print(f\"OUT[{idx}] {tuple(t.shape)} {tensor_hex(t)}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "handles = [\n",
    "    net.register_forward_hook(module_forward_hook),\n",
    "    net.linear_a.register_forward_hook(module_forward_hook),\n",
    "    net.linear_b.register_forward_hook(module_forward_hook),\n",
    "    net.sum_diff.register_forward_hook(module_forward_hook),\n",
    "]\n",
    "net(x)\n",
    "for h in handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor backward hook\n",
    "Custom tensor backward hook that receives both the tensor and its grad as parameters.\n",
    "It is wrapped in an object that automatically removes the hook after it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass\n",
      "============\n",
      "Module forward hook: LinearA\n",
      "Module forward hook: LinearB\n",
      "Module forward hook: LinearB\n",
      "Module forward hook: SumDiff\n",
      "Module forward hook: Net\n",
      "\n",
      "Backward pass\n",
      "=============\n",
      "PrintTensorGrad(SumDiff IN[1])\n",
      " - Tensor: (3, 4) dcc0\n",
      " - Grad  : (3, 4)\n",
      "PrintTensorGrad(SumDiff IN[0])\n",
      " - Tensor: (3, 4) 0380\n",
      " - Grad  : (3, 4)\n",
      "PrintTensorGrad(LinearB IN[0])\n",
      " - Tensor: (3, 2) cdc0\n",
      " - Grad  : (3, 2)\n",
      "PrintTensorGrad(LinearA IN[0])\n",
      " - Tensor: (3, 2) b1c0\n",
      " - Grad  : (3, 2)\n",
      "PrintTensorGrad(LinearB IN[0])\n",
      " - Tensor: (3, 2) b1c0\n",
      " - Grad  : (3, 2)\n",
      "PrintTensorGrad(Net IN[0])\n",
      " - Tensor: (3, 2) b1c0\n",
      " - Grad  : (3, 2)\n"
     ]
    }
   ],
   "source": [
    "BackwardHookFn = Callable[[torch.Tensor, torch.Tensor], Optional[torch.Tensor]]\n",
    "\n",
    "\n",
    "def module_forward_hook(module, inputs, outputs):\n",
    "    \"\"\"Register a one time tensor hook on the inputs of a module\"\"\"\n",
    "    print(\"Module forward hook:\", module.__class__.__name__)\n",
    "    for i, tensor in enumerate(inputs):\n",
    "        ptg = PrintTensorGrad(f\"{module.__class__.__name__} IN[{i}]\")\n",
    "        one_time_tensor_hook(tensor, ptg)\n",
    "\n",
    "\n",
    "def one_time_tensor_hook(tensor: torch.Tensor, backward_hook_fn: BackwardHookFn):\n",
    "    \"\"\"Register a one time tensor hook that will receive both the tensor and the grad\"\"\"\n",
    "    def inner(grad: torch.Tensor) -> Optional[torch.Tensor]:\n",
    "        try:\n",
    "            new_grad = backward_hook_fn(tensor, grad)\n",
    "            return new_grad\n",
    "        finally:\n",
    "            handle.remove()\n",
    "\n",
    "    handle = tensor.register_hook(inner)\n",
    "\n",
    "\n",
    "class PrintTensorGrad(BackwardHookFn):\n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "\n",
    "    def __call__(self, tensor: torch.Tensor, grad: torch.Tensor) -> None:\n",
    "        print(self)\n",
    "        print(\" - Tensor:\", tuple(tensor.shape), tensor_hex(tensor))\n",
    "        print(\" - Grad  :\", tuple(grad.shape))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.label})\"\n",
    "\n",
    "\n",
    "handles = [\n",
    "    net.register_forward_hook(module_forward_hook),\n",
    "    net.linear_a.register_forward_hook(module_forward_hook),\n",
    "    net.linear_b.register_forward_hook(module_forward_hook),\n",
    "    net.sum_diff.register_forward_hook(module_forward_hook),\n",
    "]\n",
    "\n",
    "print(\"Forward pass\\n============\")\n",
    "out = net(x)\n",
    "\n",
    "print(\"\\nBackward pass\\n=============\")\n",
    "out.sum().backward()\n",
    "\n",
    "for h in handles:\n",
    "    h.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
